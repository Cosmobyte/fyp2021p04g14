{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-39a25ebb-3466-461e-8e3d-27bd07aa9ec1",
    "deepnote_cell_type": "text-cell-h1",
    "tags": []
   },
   "source": [
    "# Project 4 - Group 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-dc407522-1b85-4efc-931b-c8d57c8a74e1",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-f3683c5d-75e4-4b74-ad63-07adaefe4b9c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1003,
    "execution_start": 1622664899159,
    "source_hash": "afff01b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imported libraries go here\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from collections import Counter\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-92856d65-068a-4c22-b5c6-5d26aa6259a8",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-80a129a7-9b0e-4768-a52f-eff8db473af7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1022,
    "execution_start": 1622664900170,
    "source_hash": "c6ea81c3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def corpus_size(lines):\n",
    "    custom_tokenizer(lines)\n",
    "    print('____Corpus size____\\n\\nWords : ',tokens,'\\nCharacters: ',characters,'\\nVocabulary size: ',len(based))    \n",
    "\n",
    "with open('../Data/Emotion/train_text.txt',\"r\", encoding=\"utf8\") as file:\n",
    "    lines = file.readlines()\n",
    "# lines = open(\"\").readlines()\n",
    "def custom_tokenizer(lines):\n",
    "    global based\n",
    "    global characters\n",
    "    global tokens\n",
    "    #read the data\n",
    "    with open(lines,\"r\", encoding=\"utf8\") as file:\n",
    "        lines = file.readlines()\n",
    "    #Initialize 2 lists, one containing all real words, as they are presented in the data, another with all words lowercase\n",
    "    all_words = []\n",
    "    based_words = []\n",
    "    characters = 0 #Used to keep track of the total number of characters in data\n",
    "    tokens = 0 # Used to keep track of the total number of tokens in data\n",
    "    #for every tweet in the data... \n",
    "    for i in lines:\n",
    "        characters += len(i)\n",
    "        #find all \"words\" in the data \n",
    "        unfiltered_tokens = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\",i) \n",
    "        #Initialize a list containing all \"non-words\" tokens\n",
    "        non_words = []\n",
    "        for g in range(len(unfiltered_tokens)):\n",
    "            #if token is specifically: ' append to unfiltered (had problems with apostrophe)\n",
    "            if bool(re.match(r'\\'',unfiltered_tokens[g])):\n",
    "                non_words.append(unfiltered_tokens[g])\n",
    "            #if token is not \n",
    "            elif not bool(re.match('^[a-zA-Z0-9\\']+$',unfiltered_tokens[g])):\n",
    "                non_words.append(unfiltered_tokens[g])\n",
    "        #initialize list of all words lowered, if they are not present in non_words\n",
    "        words = [x.lower() for x in unfiltered_tokens if x not in non_words and x !=\"user\"]\n",
    "        based_words.extend(words)\n",
    "        words = ' '.join(words)\n",
    "        all_words.append(words)\n",
    "        tokens += len(re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\",i))\n",
    "    based = Counter(based_words)\n",
    "    return all_words\n",
    "#Exporting the reuslts of the tokenizer\n",
    "tokenizer_words_dict = custom_tokenizer(\"../Data/Hate/train_text.txt\")\n",
    "file1 = open(\"../Data/Hate/tokenizer_text.txt\",\"w\")\n",
    "file1.writelines(tokenizer_words_dict)\n",
    "file1.close() \n",
    "tokenizer_words_dict = custom_tokenizer(\"../Data/Emotion/train_text.txt\")\n",
    "file2 = open(\"../Data/Emotion/tokenizer_text.txt\",\"w\")\n",
    "file2.writelines(tokenizer_words_dict)\n",
    "file2.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-617ed597-5917-44f5-85c5-c905fa5c6589",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "### Characterizing your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-07243b3b-5f9d-4153-af7d-2072705ce044",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2092,
    "execution_start": 1622664901227,
    "source_hash": "b617dc22",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using the teachers code from lecture 2 to plot zipf's law in the plots below with minor modifications\n",
    "#taken from https://learnit.itu.dk/pluginfile.php/296257/mod_resource/content/1/zipf.py\n",
    "\n",
    "#Plotting for the hate dataset\n",
    "\n",
    "#running the tokenizer to get the global variable\n",
    "not_relevant = custom_tokenizer(\"../Data/Hate/train_text.txt\")\n",
    "frq = pd.DataFrame(based.most_common(), columns=['token', 'frequency'])\n",
    "# Index in the sorted list\n",
    "frq['idx'] = frq.index + 1\n",
    "\n",
    "# Frequency normalised by corpus size\n",
    "frq['norm_freq'] = frq.frequency / len(based)\n",
    "\n",
    "# Cumulative normalised frequency\n",
    "frq['cumul_frq'] = frq.norm_freq.cumsum()\n",
    "\n",
    "seaborn.set_theme(style='whitegrid')\n",
    "\n",
    "# Plot: Cumulative frequency by index, top 10000 tokens\n",
    "seaborn.relplot(x='idx', y='cumul_frq', data=frq[:10000], kind='line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-3ac3bf15-5dd4-4d98-ab3f-43fae41b55f7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 489,
    "execution_start": 1622664903300,
    "source_hash": "3d85f29c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Log-log plot for Zipf's law\n",
    "frq['log_frq'] = numpy.log(frq.frequency)\n",
    "frq['log_rank'] = numpy.log(frq.frequency.rank(ascending=False))\n",
    "seaborn.relplot(x='log_rank', y='log_frq', data=frq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-a297d8d6-c459-48ee-8927-35e5901d9ce7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1221,
    "execution_start": 1622664903781,
    "source_hash": "7c453268",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting for the emotion dataset\n",
    "#running the tokenizer to get the global variable \"based\"\n",
    "not_relevant = custom_tokenizer(\"../Data/Emotion/train_text.txt\")\n",
    "frq = pd.DataFrame(based.most_common(), columns=['token', 'frequency'])\n",
    "\n",
    "# Index in the sorted list\n",
    "frq['idx'] = frq.index + 1\n",
    "\n",
    "# Frequency normalised by corpus size\n",
    "frq['norm_freq'] = frq.frequency / len(based)\n",
    "\n",
    "# Cumulative normalised frequency\n",
    "frq['cumul_frq'] = frq.norm_freq.cumsum()\n",
    "\n",
    "# Plot: Cumulative frequency by index, top 10000 tokens\n",
    "seaborn.relplot(x='idx', y='cumul_frq', data=frq, kind='line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-45320078-6b59-4104-9148-45e85feaeee2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 535,
    "execution_start": 1622664905041,
    "source_hash": "3d85f29c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot: Log-log plot for Zipf's law\n",
    "frq['log_frq'] = numpy.log(frq.frequency)\n",
    "frq['log_rank'] = numpy.log(frq.frequency.rank(ascending=False))\n",
    "seaborn.relplot(x='log_rank', y='log_frq', data=frq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-d49a5f5c-6f22-414a-afde-92a23249712e",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "### Manual Annotation and Inter-Annotation Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-ffa79ed0-3048-4468-91d4-5ff09263d903",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 155,
    "execution_start": 1622664905621,
    "source_hash": "1abe2894",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cohen's Kappa\n",
    "\n",
    "def kappa(h):\n",
    "    h2 = open(\"../Data/Hate/train_labels.txt\", \"r\").readlines()[:100]\n",
    "    index = 0\n",
    "    errors = 0\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    d = 0\n",
    "    print(\"--- hate ---\")\n",
    "    print(\"(0:non-hate, 1:hate)\")\n",
    "    for hm, testhm in zip(h,h2):\n",
    "        index += 1\n",
    "        if hm[0] != testhm[0]:\n",
    "            errors += 1\n",
    "            print(\"line:\", index, \"  error:\", hm[0], \":\", testhm[0])\n",
    "        if hm[0] == '1':\n",
    "            if testhm[0] == '1':\n",
    "                a += 1\n",
    "            elif testhm[0] == '0':\n",
    "                b += 1\n",
    "        elif hm[0] == '0':\n",
    "            if testhm[0] == '1':\n",
    "                c += 1\n",
    "            elif testhm[0] == '0':\n",
    "                d += 1\n",
    "    p0 = (a+d)/(a+b+c+d)\n",
    "    pyes = ((a+b)/(a+b+c+d))*((a+b)/(a+b+c+d))\n",
    "    pno = ((c+d)/(a+b+c+d))*((b+d)/(a+b+c+d))\n",
    "    pe = (pyes + pno)\n",
    "    print(\"---\")\n",
    "    print(\"p0: \", p0) #percentage correct\n",
    "    print(\"pyes: \", pyes) #probability that both were randomly labeled as hate\n",
    "    print(\"pno: \", pno) #probability both were randomly labeled as non-hate\n",
    "    print(\"pe: \", pe) #overall random agreement probability \n",
    "    print(\"Agreement: \", ((p0 - pe)/(1-pe))) #inter-rater reliability\n",
    "    return p0,pe\n",
    "\n",
    "h1 = open(\"../Data/Hate/Christian_train_labels.txt\", \"r\").readlines()\n",
    "h2 = open(\"../Data/Hate/Cosmin_train_labels.txt\", \"r\").readlines()\n",
    "h3 = open(\"../Data/Hate/Daniel_train_labels.txt\", \"r\").readlines()\n",
    "h4 = open(\"../Data/Hate/Jacob_train_labels.txt\", \"r\").readlines()\n",
    "\n",
    "print(\"Christian's\")\n",
    "p0_1,pe_1 = kappa(h1)\n",
    "print(\"---------------------\")\n",
    "print(\"Cosmin's\")\n",
    "p0_2,pe_2 = kappa(h2)\n",
    "print(\"---------------------\")\n",
    "print(\"Daniel's\")\n",
    "p0_3,pe_3 = kappa(h3)\n",
    "print(\"---------------------\")\n",
    "print(\"Jacob's\")\n",
    "p0_4,pe_4 = kappa(h4)\n",
    "\n",
    "#calculating the average\n",
    "p0_average = (p0_1+p0_2+p0_3+p0_4)/4\n",
    "pe_average = (pe_1+pe_2+pe_3+pe_4)/4\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"Average score\")\n",
    "print(\"p0: \", p0_average)\n",
    "print(\"pe: \", pe_average)\n",
    "print(\"Agreement: \",((p0_average - pe_average)/(1-pe_average)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-591a716e-c3a6-4384-a2c0-ccf18edcf358",
    "deepnote_cell_type": "text-cell-h3",
    "tags": []
   },
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hate speech dataset using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-5bc6986f-c40f-4b35-8eb1-1f8f0ae329cd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 159628,
    "execution_start": 1622664905770,
    "source_hash": "5198b4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = custom_tokenizer('../Data/Hate/train_text.txt')\n",
    "with open(\"../Data/Hate/train_labels.txt\", \"r\") as fd:\n",
    "    y_train = fd.read().splitlines()\n",
    "with open(\"../Data/Hate/val_labels.txt\", \"r\") as fd:\n",
    "    y_val = fd.read().splitlines()\n",
    "tokenizer_val_set = custom_tokenizer(\"../Data/Hate/val_text.txt\")\n",
    "#Using 932 features for max features since the test set can support just 932 features and the classifier needs the same number of features\n",
    "#for the training and validation set\n",
    "CV = CountVectorizer(max_features=932, min_df=5, max_df=0.7,analyzer='word', ngram_range=(1, 3))\n",
    "x1_train = CV.fit_transform(X)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(x1_train, y_train)\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier_sgd = SGDClassifier(alpha=0.00001,loss = \"perceptron\")\n",
    "clf_sgd= classifier_sgd.fit(x1_train,y_train)\n",
    "rf = classifier_rf.fit(x1_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-70db35f3-1122-4cf1-be1f-e71b64ede469",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 900,
    "execution_start": 1622665065440,
    "source_hash": "40d5be04",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "CV2 = CountVectorizer(max_features=932, min_df=5, max_df=0.7,analyzer='word', ngram_range=(1, 3))\n",
    "x1_test = CV2.fit_transform(tokenizer_val_set)\n",
    "y_pred = rf.predict(x1_test)\n",
    "y_pred1 = clf_sgd.predict(x1_test)\n",
    "y_pred_mlp= clf_mlp.predict(x1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-f46453cc-32e1-48b7-a01d-28762e38a522",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1622665066355,
    "source_hash": "2be89c05",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(CV2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-9ab09c5c-076a-4da1-8579-45703577ef42",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 79,
    "execution_start": 1622665066431,
    "source_hash": "6f0d9bb0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(confusion_matrix(y_val,y_pred))\n",
    "print(classification_report(y_val,y_pred))\n",
    "print(accuracy_score(y_val, y_pred))\n",
    "print(confusion_matrix(y_val,y_pred1))\n",
    "print(classification_report(y_val,y_pred1))\n",
    "print(accuracy_score(y_val, y_pred1))\n",
    "print(confusion_matrix(y_val,y_pred_mlp))\n",
    "print(classification_report(y_val,y_pred_mlp))\n",
    "print(accuracy_score(y_val, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-8328a2c6-8906-4c29-a9cb-859db96ce476",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 98564,
    "execution_start": 1622665066510,
    "source_hash": "400c0414",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# with open(\"../Data/Hate/train_labels.txt\", \"r\") as fd:\n",
    "#     y_train = fd.read().splitlines()\n",
    "tfidfconverter = TfidfVectorizer(max_features=911, min_df=5, max_df=0.7,analyzer = 'word',ngram_range=(1, 2))\n",
    "X_train = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "classifier_sgd = SGDClassifier(alpha=0.00001,loss = \"perceptron\")\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "rf2  = classifier_rf.fit(X_train, y_train)\n",
    "sgd2 = classifier_sgd.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00015-26dff1f6-7a9d-4d21-b066-0c3f4c4dcf1d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 964,
    "execution_start": 1622665165074,
    "source_hash": "bfe89468",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer_words_dict2 = custom_tokenizer(\"../Data/Hate/val_text.txt\")\n",
    "tfidfconverter2 = TfidfVectorizer(max_features=911, min_df=5, max_df=0.7,analyzer = 'word',ngram_range=(1, 2))\n",
    "X_test = tfidfconverter2.fit_transform(tokenizer_val_set).toarray()\n",
    "\n",
    "y_pred2 = rf2.predict(X_test)\n",
    "y_pred3 = sgd2.predict(X_test)\n",
    "y_pred_mlp_val = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-e6750702-2d17-4116-9f5e-67459e50293d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1622665166049,
    "source_hash": "2ef9d015",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tfidfconverter2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-e73d3b98-5178-4c19-8b59-2f8af8244766",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 100,
    "execution_start": 1622665166060,
    "source_hash": "38ccc619",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(\"../Data/Hate/val_labels.txt\", \"r\") as fd:\n",
    "#     y_test = fd.read().splitlines()\n",
    "print(confusion_matrix(y_val,y_pred2))\n",
    "print(classification_report(y_val,y_pred2))\n",
    "print(accuracy_score(y_val, y_pred2))\n",
    "print(confusion_matrix(y_val,y_pred3))\n",
    "print(classification_report(y_val,y_pred3))\n",
    "print(accuracy_score(y_val, y_pred3))\n",
    "print(confusion_matrix(y_val,y_pred_mlp_val))\n",
    "print(classification_report(y_val,y_pred_mlp_val))\n",
    "print(accuracy_score(y_val, y_pred_mlp_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion dataset,Count Vectorizer,validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-e684ece3-08c4-49cd-adfb-3c89509f7d2e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 57857,
    "execution_start": 1622665166209,
    "source_hash": "2e3560f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "with open(\"../Data/Emotion/train_labels.txt\", \"r\") as fd:\n",
    "    y_train_emotion = fd.read().splitlines()\n",
    "X_emotion = custom_tokenizer(\"../Data/Emotion/train_text.txt\")\n",
    "tokenizer_emotion_val_set = custom_tokenizer(\"../Data/Emotion/val_text.txt\")\n",
    "with open(\"../Data/Emotion/val_labels.txt\", \"r\") as fd:\n",
    "    y_val_emotion = fd.read().splitlines()\n",
    "\n",
    "CV = CountVectorizer(max_features=405, min_df=3, max_df=0.8,analyzer='word', ngram_range=(1, 3))\n",
    "x1_train_emotion = CV.fit_transform(X_emotion)\n",
    "\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(x1_train_emotion, y_train_emotion)\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier_sgd = SGDClassifier(alpha=0.00001,loss = \"log\")\n",
    "clf_sgd= classifier_sgd.fit(x1_train_emotion,y_train_emotion)\n",
    "rf = classifier_rf.fit(x1_train_emotion, y_train_emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00022-534246e8-942e-43bd-b88e-6dea0bd0a18a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 493,
    "execution_start": 1622665224069,
    "source_hash": "94ec6b30",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "CV2 = CountVectorizer(max_features=405, min_df=3, max_df=0.8,analyzer='word', ngram_range=(1, 3))\n",
    "x1_test = CV2.fit_transform(tokenizer_emotion_val_set)\n",
    "y_pred = rf.predict(x1_test)\n",
    "y_pred1 = clf_sgd.predict(x1_test)\n",
    "y_pred_mlpx= clf_mlp.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00023-c7b1c50e-62e1-4529-bff2-4d62ddceefd9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1622665224569,
    "source_hash": "2be89c05",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(CV2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00023-7bb0e873-4f00-4883-85f5-db31cd80e25c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 73,
    "execution_start": 1622665224577,
    "source_hash": "a8f1178e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(confusion_matrix( y_val_emotion,y_pred))\n",
    "print(classification_report( y_val_emotion,y_pred))\n",
    "print(accuracy_score( y_val_emotion, y_pred))\n",
    "print(confusion_matrix( y_val_emotion,y_pred1))\n",
    "print(classification_report( y_val_emotion,y_pred1))\n",
    "print(accuracy_score( y_val_emotion, y_pred1))\n",
    "print(confusion_matrix( y_val_emotion,y_pred_mlpx))\n",
    "print(classification_report( y_val_emotion,y_pred_mlpx))\n",
    "print(accuracy_score( y_val_emotion, y_pred_mlpx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00024-dd715b7c-7760-4010-bd16-8d264c886d40",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 100876,
    "execution_start": 1622665224654,
    "source_hash": "ccfbeb14",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=405, min_df=3, max_df=0.8,analyzer = 'word',ngram_range=(1, 3))\n",
    "X_train_emotion = tfidfconverter.fit_transform(X_emotion).toarray()\n",
    "\n",
    "classifier_sgd = SGDClassifier(alpha=0.00001,loss = \"perceptron\")\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0,criterion=\"entropy\")\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(X_train_emotion, y_train_emotion)\n",
    "rf2  = classifier_rf.fit(X_train_emotion, y_train_emotion)\n",
    "sgd2 = classifier_sgd.fit(X_train_emotion,y_train_emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00026-61f231a8-1e8c-4e21-9f46-fda2c5feb64d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 561,
    "execution_start": 1622665342875,
    "source_hash": "615e3b68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidfconverter2 = TfidfVectorizer(max_features=405, min_df=3, max_df=0.8,analyzer = 'word',ngram_range=(1, 3))\n",
    "X_test = tfidfconverter2.fit_transform(tokenizer_emotion_val_set).toarray()\n",
    "\n",
    "y_pred2 = rf2.predict(X_test)\n",
    "y_pred3 = sgd2.predict(X_test)\n",
    "y_pred4 = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-fded490a-b20e-449b-a658-d7face29fcc1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1622665325635,
    "source_hash": "2ef9d015",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tfidfconverter2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-30476b20-8b21-4ba1-8593-48dc21b90174",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 32,
    "execution_start": 1622665345835,
    "source_hash": "66a0c06",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_val_emotion,y_pred2))\n",
    "print(classification_report(y_val_emotion,y_pred2))\n",
    "print(accuracy_score(y_val_emotion, y_pred2))\n",
    "print(confusion_matrix(y_val_emotion,y_pred3))\n",
    "print(classification_report(y_val_emotion,y_pred3))\n",
    "print(accuracy_score(y_val_emotion, y_pred3))\n",
    "print(confusion_matrix(y_val_emotion,y_pred4))\n",
    "print(classification_report(y_val_emotion,y_pred4))\n",
    "print(accuracy_score(y_val_emotion, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-7b199904-bfbb-4425-97da-1762b5f7f472",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00029-05e07384-afb8-4b5a-9c93-6da3ad581692",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 232904,
    "execution_start": 1622665353627,
    "source_hash": "48f2e832",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "with open(\"../Data/Hate/train_labels.txt\", \"r\") as fd:\n",
    "    y_train = fd.read().splitlines()\n",
    "tokenizer_test_set_hate = custom_tokenizer(\"../Data/Hate/test_text.txt\")\n",
    "with open(\"../Data/Hate/test_labels.txt\", \"r\") as fd:\n",
    "    y_test = fd.read().splitlines()\n",
    "\n",
    "CV = CountVectorizer(max_features=2500, min_df=5, max_df=0.7,analyzer='word', ngram_range=(1, 2))\n",
    "x1_train = CV.fit_transform(X)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(x1_train, y_train)\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier_sgd = SGDClassifier(alpha=0.0001,loss = \"log\")\n",
    "clf_sgd= classifier_sgd.fit(x1_train,y_train)\n",
    "rf = classifier_rf.fit(x1_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00030-27612b21-3c21-4cfb-94b4-0fb6f8320f2f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2755,
    "execution_start": 1622665586576,
    "source_hash": "d1f3a281",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CV2 = CountVectorizer(max_features=2500, min_df=5, max_df=0.7,analyzer='word', ngram_range=(1, 2))\n",
    "x1_test = CV2.fit_transform(tokenizer_test_set_hate)\n",
    "y_pred = rf.predict(x1_test)\n",
    "y_pred1 = clf_sgd.predict(x1_test)\n",
    "y_pred_mlp= clf_mlp.predict(x1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00032-d45c5041-b298-4a79-91c5-cdc25b9ea1e2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 238,
    "execution_start": 1622665589334,
    "source_hash": "5fe628d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(classification_report(y_test,y_pred1))\n",
    "print(accuracy_score(y_test, y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred_mlp))\n",
    "print(classification_report(y_test,y_pred_mlp))\n",
    "print(accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00033-7d335dd7-ee93-4219-ace4-7cfb86447f19",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 545329,
    "execution_start": 1622665589609,
    "source_hash": "93a47afb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=2541, min_df=5, max_df=0.7,analyzer = 'word',ngram_range=(1, 2))\n",
    "X_train = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "classifier_sgd = SGDClassifier(alpha=0.001,loss = \"log\")\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(X_train, y_train)\n",
    "rf2  = classifier_rf.fit(X_train, y_train)\n",
    "sgd2 = classifier_sgd.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00034-68694303-d1e6-4581-be8c-6f082aed10d0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5311,
    "execution_start": 1622666134938,
    "source_hash": "62588f8f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_words_dict2 = custom_tokenizer(\"../Data/Hate/test_text.txt\")\n",
    "tfidfconverter2 = TfidfVectorizer(max_features=2541,min_df=5, max_df=0.7,analyzer = 'word',ngram_range=(1, 2))\n",
    "X_test = tfidfconverter2.fit_transform(tokenizer_words_dict2).toarray()\n",
    "\n",
    "y_pred2 = rf2.predict(X_test)\n",
    "y_pred3 = sgd2.predict(X_test)\n",
    "y_pred_mlp = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-4a2ba374-e197-4740-911b-e10143bba035",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12,
    "execution_start": 1622666140256,
    "source_hash": "2ef9d015",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tfidfconverter2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-51aec10e-1af0-45a4-8131-12a31daa9a9d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 241,
    "execution_start": 1622666140264,
    "source_hash": "ce6e8826",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/Hate/test_labels.txt\", \"r\") as fd:\n",
    "    y_test = fd.read().splitlines()\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(classification_report(y_test,y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(classification_report(y_test,y_pred3))\n",
    "print(accuracy_score(y_test, y_pred3))\n",
    "print(confusion_matrix(y_test,y_pred_mlp))\n",
    "print(classification_report(y_test,y_pred_mlp))\n",
    "print(accuracy_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion dataset,test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-458ccff7-4ea4-4864-8f2f-a4a32e69c5c4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 72728,
    "execution_start": 1622666140529,
    "source_hash": "56a680c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_emotion_test_set = custom_tokenizer(\"../Data/Emotion/test_text.txt\")\n",
    "with open(\"../Data/Emotion/test_labels.txt\", \"r\") as fd:\n",
    "    y_test_emotion = fd.read().splitlines()\n",
    "\n",
    "CV = CountVectorizer(max_features=1657, min_df=3, max_df=0.8,analyzer='word', ngram_range=(1, 4))\n",
    "x1_train = CV.fit_transform(X_emotion)\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(x1_train, y_train_emotion)\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier_sgd = SGDClassifier(alpha=0.00001,loss = \"perceptron\")\n",
    "clf_sgd= classifier_sgd.fit(x1_train,y_train_emotion)\n",
    "rf = classifier_rf.fit(x1_train, y_train_emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00037-142714b3-fbc1-49b9-81a6-21ff4a47b2bd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1448,
    "execution_start": 1622666213302,
    "source_hash": "d4fc992d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "CV2 = CountVectorizer(max_features=1657, min_df=3, max_df=0.8,analyzer='word', ngram_range=(1, 4))\n",
    "x1_test = CV2.fit_transform(tokenizer_emotion_test_set)\n",
    "y_pred = rf.predict(x1_test)\n",
    "y_pred1 = clf_sgd.predict(x1_test)\n",
    "y_pred_mlp2= clf_mlp.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00039-afa2c2a5-17de-45a0-b399-3f980c3bda31",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 18,
    "execution_start": 1622666214760,
    "source_hash": "2be89c05",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(CV2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00038-2626ae02-79c8-4b9c-99f4-94c8ae87ab5e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 162,
    "execution_start": 1622666214771,
    "source_hash": "3aa45e4f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_test_emotion,y_pred))\n",
    "print(classification_report(y_test_emotion,y_pred))\n",
    "print(accuracy_score(y_test_emotion, y_pred))\n",
    "print(confusion_matrix(y_test_emotion,y_pred1))\n",
    "print(classification_report(y_test_emotion,y_pred1))\n",
    "print(accuracy_score(y_test_emotion, y_pred1))\n",
    "print(confusion_matrix(y_test_emotion,y_pred1))\n",
    "print(classification_report(y_test_emotion,y_pred_mlp2))\n",
    "print(accuracy_score(y_test_emotion,y_pred_mlp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00039-fd6c972b-2edf-47ef-b5bc-224682058f24",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 207008,
    "execution_start": 1622666214936,
    "source_hash": "262d653",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1657,min_df=5, max_df=0.8,analyzer = 'word',ngram_range=(1, 3))\n",
    "X_train = tfidfconverter.fit_transform(X_emotion).toarray()\n",
    "\n",
    "classifier_sgd = SGDClassifier(alpha=0.00001,loss = \"perceptron\")\n",
    "classifier_rf = RandomForestClassifier(n_estimators=1000, random_state=0,criterion=\"entropy\")\n",
    "clf_mlp = MLPClassifier(random_state=1, max_iter=1000).fit(X_train, y_train_emotion)\n",
    "rf2  = classifier_rf.fit(X_train, y_train_emotion)\n",
    "sgd2 = classifier_sgd.fit(X_train,y_train_emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00040-f3e29e77-0eb6-4877-adfa-5c8dc98779b7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1745,
    "execution_start": 1622666421987,
    "source_hash": "2a182919",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidfconverter2 = TfidfVectorizer(max_features=1657,min_df=3, max_df=0.8,analyzer = 'word',ngram_range=(1, 4))\n",
    "X_test = tfidfconverter2.fit_transform(tokenizer_emotion_test_set).toarray()\n",
    "\n",
    "y_pred2 = rf2.predict(X_test)\n",
    "y_pred3 = sgd2.predict(X_test)\n",
    "y_pred4 = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00043-f47e57f3-9e15-4203-8be4-bf1cd8eacd8b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1622666423732,
    "source_hash": "2ef9d015",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tfidfconverter2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00041-9b7e1f67-aceb-4d50-9220-be7570f72152",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 127,
    "execution_start": 1622666423742,
    "source_hash": "913186ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_test_emotion,y_pred2))\n",
    "print(classification_report(y_test_emotion,y_pred2))\n",
    "print(accuracy_score(y_test_emotion, y_pred2))\n",
    "print(confusion_matrix(y_test_emotion,y_pred3))\n",
    "print(classification_report(y_test_emotion,y_pred3))\n",
    "print(accuracy_score(y_test_emotion, y_pred3))\n",
    "print(confusion_matrix(y_test_emotion,y_pred4))\n",
    "print(classification_report(y_test_emotion,y_pred4))\n",
    "print(accuracy_score(y_test_emotion, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e5405d22-c95f-4297-8af0-413a9a0a4e10",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
